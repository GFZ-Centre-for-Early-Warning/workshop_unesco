{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Image Analysis\n",
    "## Pixel based supervised landuse classification\n",
    "\n",
    "This exercise deals with a simple supervised landuse classification using only freely available data\n",
    "and software. \n",
    "\n",
    "We will use free of cost satellite imagery\n",
    "![title](img/landsat.jpg)\n",
    "\n",
    "* Medium resolution 30mx30m (Panchromatic band with 15m x 15m)\n",
    "* 11 spectral bands\n",
    "\n",
    "**Operational Land Imager (OLI)**\n",
    "\n",
    "| Spectral Band \t                 | Wavelength \t    |Resolution |\n",
    "|:----------------------------------:|:----------------:|:---------:|\n",
    "| Band 1 - Coastal / Aerosol \t     | 0.433 – 0.453 µm | 30 m      |\n",
    "| Band 2 - Blue \t                 | 0.450 – 0.515 µm | 30 m      |\n",
    "| Band 3 - Green \t                 | 0.525 – 0.600 µm | 30 m      |\n",
    "| Band 4 - Red \t                     | 0.630 – 0.680 µm | 30 m      |\n",
    "| Band 5 - Near Infrared \t         | 0.845 – 0.885 µm | 30 m      |\n",
    "| Band 6 - Short Wavelength Infrared | 1.560 – 1.660 µm | 30 m      |\n",
    "| Band 7 - Short Wavelength Infrared | 2.100 – 2.300 µm | 30 m      |\n",
    "| Band 8 - Panchromatic \t         | 0.500 – 0.680 µm | 15 m      |\n",
    "| Band 9 - Cirrus \t                 | 1.360 – 1.390 µm | 30 m      |\n",
    "\n",
    "**Thermal Infrared Sensors (TIRS)**\n",
    "\n",
    "| Spectral Band                      | \t Wavelength       |  Resolution |\n",
    "|:----------------------------------:|:------------------:|:-----------:|\n",
    "| Band 10 - Long Wavelength Infrared | \t10.30 – 11.30 µm  |     100 m   |\n",
    "| Band 11 - Long Wavelength Infrared |\t11.50 – 12.50 µm  |\t    100 m   |\n",
    "\n",
    "\n",
    "Also older free data is available, as early as the 70s.\n",
    "\n",
    "For visualization and digitizing we will use a free of cost and open source Geographic Information System (GIS)\n",
    "![title](img/qgis.png)\n",
    "\n",
    "We will use high resolution imagery from \n",
    "![title](img/google.jpg)\n",
    "\n",
    "to classify different landuse types \n",
    "\n",
    "For image processing we will rely on the tools from the \n",
    "![title](img/otb1.png)\n",
    "\n",
    "\n",
    "\n",
    "### Where to get the data\n",
    "\n",
    "For Landsat there are several possibilities to get the data. We will only discuss the \n",
    "online platform [Earth Explorer](https://earthexplorer.usgs.gov/) \n",
    "\n",
    "Let's go through the steps how to download satellite imagery (requires registration).\n",
    "\n",
    "We saw:\n",
    "* There is all kinds of satellite data available free of cost\n",
    "* I can easily find satellite data if I know the name, address or location of the place I am interested in\n",
    "* The small thumbnails give me a good idea of the cloud coverage of the scene\n",
    "* Clicking on the thumbnail I get more information about the acquisition conditions\n",
    "* Clicking on the small footprint one can see which part of the earth surface is covered by the scene\n",
    "* Usually we want Level 1 products for our analysis (Landsat 8 ~ 1GB per scene)\n",
    "\n",
    "Once you have downloaded a scene you should have a gun-zipped tarball (tar.gz archive) which contains all the bands and some more information about the scene.\n",
    "\n",
    "For the purpose of this exercise we don't download the data since one scene is about 1 GB in size. Instead\n",
    "we use a scene we downloaded from the Earth Explorer platform and is already located on the Desktop of\n",
    "the machine. It is in the directory **/home/sysop/Desktop/RSData**.\n",
    "\n",
    "Let's create a new directory on the Desktop and untar the tarball there.\n",
    "\n",
    "### Visualizing layers in QGIS\n",
    "Let's take a look at the data in QGIS together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"qgis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data collected by the sensor on the satellite and processed by USGS/NASA to a Level 1 product is stored in separate TIF Files. \n",
    "* Each band is stored in a different file.\n",
    "* TIF is a raster format. Basically this means the data is stored on a georeferenced grid.\n",
    "* Because the grid is georeferenced we can visualize it easily with the correct location in a GIS system!\n",
    "* The pixels of Band 8 do not overlap exactly with the other Bands pixels! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A tool for classification\n",
    "Now we want to use these images to obtain a landuse classification (focusing on built up areas), that will give us \n",
    "a basic understanding of how our town is structured.\n",
    "\n",
    "For doing so, we can use a tool developed at GFZ for simple pixel based Landuse Classification.\n",
    "**The REM SatEx tool**. \n",
    "It is already installed on the machine used during the training. \n",
    "Otherwise you can get it from our [github repository](https://github.com/GFZ-Centre-for-Early-Warning/REM_satex_plugin).\n",
    "\n",
    "This tool is designed as QGIS plugin but we will use it as a python script within this workshop.\n",
    "\n",
    "The plugin requires an installation of the [Orfeo Toolbox](www.orfeo-toolbox.org). On Windows you can install it\n",
    "via OSGeo4W on Linux you can install it from packages provided\n",
    "by your distribution or build it from the source packages available\n",
    "from its git repository.\n",
    "\n",
    "Note: Some Linux distributions split OTB in different packages,\n",
    "in order for this plugin to work make sure the python wrappers\n",
    "are installed alongside with the otb library. You can check if OTB\n",
    "and the wrappers are installed from within qgis by opening the \n",
    "Python Console and executing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BandMath',\n",
       " 'BinaryMorphologicalOperation',\n",
       " 'BlockMatching',\n",
       " 'BundleToPerfectSensor',\n",
       " 'ClassificationMapRegularization',\n",
       " 'ColorMapping',\n",
       " 'CompareImages',\n",
       " 'ComputeConfusionMatrix',\n",
       " 'ComputeImagesStatistics',\n",
       " 'ComputeOGRLayersFeaturesStatistics',\n",
       " 'ComputePolylineFeatureFromImage',\n",
       " 'ConcatenateImages',\n",
       " 'ConcatenateVectorData',\n",
       " 'ConnectedComponentSegmentation',\n",
       " 'Convert',\n",
       " 'ConvertCartoToGeoPoint',\n",
       " 'ConvertSensorToGeoPoint',\n",
       " 'DEMConvert',\n",
       " 'DSFuzzyModelEstimation',\n",
       " 'Despeckle',\n",
       " 'DimensionalityReduction',\n",
       " 'DisparityMapToElevationMap',\n",
       " 'DomainTransform',\n",
       " 'DownloadSRTMTiles',\n",
       " 'EdgeExtraction',\n",
       " 'ExtractROI',\n",
       " 'FineRegistration',\n",
       " 'FusionOfClassifications',\n",
       " 'GeneratePlyFile',\n",
       " 'GenerateRPCSensorModel',\n",
       " 'GrayScaleMorphologicalOperation',\n",
       " 'GridBasedImageResampling',\n",
       " 'HaralickTextureExtraction',\n",
       " 'HomologousPointsExtraction',\n",
       " 'HooverCompareSegmentation',\n",
       " 'HyperspectralUnmixing',\n",
       " 'ImageClassifier',\n",
       " 'ImageEnvelope',\n",
       " 'KMeansClassification',\n",
       " 'KmzExport',\n",
       " 'LSMSSegmentation',\n",
       " 'LSMSSmallRegionsMerging',\n",
       " 'LSMSVectorization',\n",
       " 'LineSegmentDetection',\n",
       " 'LocalStatisticExtraction',\n",
       " 'ManageNoData',\n",
       " 'MeanShiftSmoothing',\n",
       " 'MultiImageSamplingRate',\n",
       " 'MultiResolutionPyramid',\n",
       " 'MultivariateAlterationDetector',\n",
       " 'OGRLayerClassifier',\n",
       " 'OSMDownloader',\n",
       " 'ObtainUTMZoneFromGeoPoint',\n",
       " 'OpticalCalibration',\n",
       " 'OrthoRectification',\n",
       " 'Pansharpening',\n",
       " 'PixelValue',\n",
       " 'PolygonClassStatistics',\n",
       " 'PredictRegression',\n",
       " 'Quicklook',\n",
       " 'RadiometricIndices',\n",
       " 'Rasterization',\n",
       " 'ReadImageInfo',\n",
       " 'RefineSensorModel',\n",
       " 'Rescale',\n",
       " 'RigidTransformResample',\n",
       " 'SARCalibration',\n",
       " 'SARDecompositions',\n",
       " 'SARPolarMatrixConvert',\n",
       " 'SARPolarSynth',\n",
       " 'SFSTextureExtraction',\n",
       " 'SOMClassification',\n",
       " 'SampleExtraction',\n",
       " 'SampleSelection',\n",
       " 'SarRadiometricCalibration',\n",
       " 'Segmentation',\n",
       " 'Smoothing',\n",
       " 'SplitImage',\n",
       " 'StereoFramework',\n",
       " 'StereoRectificationGridGenerator',\n",
       " 'Superimpose',\n",
       " 'TestApplication',\n",
       " 'TileFusion',\n",
       " 'TrainImagesClassifier',\n",
       " 'TrainOGRLayersClassifier',\n",
       " 'TrainRegression',\n",
       " 'TrainVectorClassifier',\n",
       " 'VectorDataDSValidation',\n",
       " 'VectorDataExtractROI',\n",
       " 'VectorDataReprojection',\n",
       " 'VectorDataSetField',\n",
       " 'VectorDataTransform',\n",
       " 'VertexComponentAnalysis')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import otbApplication\n",
    "otbApplication.Registry.GetAvailableApplications()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should return you a list of otb functions if you installed **OTB** correctly.\n",
    "\n",
    "** Purpose of the Plugin **\n",
    "\n",
    "The Plugin provides two algorithms for the processing of one or\n",
    "multiple Landsat scenes within a region of interest towards a\n",
    "Landuse/Landcoverage classification streamlining all required processing\n",
    "steps to perform a libsvm/orfeo toolbox (OTB) pixel based\n",
    "classification.\n",
    "\n",
    "The two algorithms are\n",
    "\n",
    "1. Preprocessing, and\n",
    "\n",
    "2. Classification\n",
    "\n",
    "In the **Preprocessing** algorithm Landsat scenes located in a\n",
    "directory as , e.g., the directory created by extracting from the\n",
    "downloaded zip archive of a Landsat 8 scene as can be found on\n",
    "[EarthExplorer](http://earthexplorer.usgs.gov/) is \n",
    "1. cropped to a region of interest provided as , e.g., a polygon feature in a vector file and then \n",
    "2. the separate spectral Bands are stacked and \n",
    "3. a virtual raster tile is created out of these  \n",
    "\n",
    "If present,the panchromatic band 8 (Landsat 7 and 8) is excluded from the layers. \n",
    "\n",
    "The **Classification** algorithm is performing a classification of a raster\n",
    "file as, e.g., resulting from the **Preprocessing** algorithm and either\n",
    "by using\n",
    "1. a provided trained Support Vector Model (SVM) from OTB or\n",
    "2. training and testing a SVM on the fly using a provided ground truth testing/training data set. \n",
    "\n",
    "For case 2) a on the fly training/testing is performed:\n",
    "* provided ground truth data is randomly split in a testing (~20%) and a training part (~80%), \n",
    "* the latter is then used in the libsvm implementation of OTB to create a **SVM**. \n",
    " \n",
    "This SVM (or the external SVM) are then used to \n",
    "1. classify the image. \n",
    "2. The resulting raster file with class labels is then tested with the testing dataset (all features of the provided vector layer in case an external SVM model was provided)\n",
    "3. and a confusion matrix is produced. \n",
    "4. Finally the resulting raster file is sieved (i.e., regions consisting of view pixels are merged to the surrounding).\n",
    "\n",
    "\n",
    "#### Preparing the input\n",
    "We have already done the first step:\n",
    "1. We downloaded a Landsat scene from Earth Explorer\n",
    "\n",
    "*Note: If we would need more then one Landsat scene, \n",
    "       we would need to store all Bands of all scenes in one directory for SatEx to find them.*\n",
    "\n",
    "The second step is to \n",
    "\n",
    "##### Generate a region of interest (ROI)\n",
    "\n",
    "As we saw the files are quite large so processing will take quite long.\n",
    "There are a couple of considerations:\n",
    "1. Often we can take only a part of the scene, cutting of parts that we are actually not interested in.\n",
    "   $\\rightarrow$ This reduces the computation costs. \n",
    "2. On the other hand, often the region in which we are interested might be only partly covered by a single scene\n",
    "   and we might need two or more neighbouring scenes.\n",
    "   $\\rightarrow$ This increases computation costs.\n",
    "   \n",
    "So let's first define a region of interest (ROI), i.e., the region in which we are actually interested for our analysis.\n",
    "This ROI can then be used to cut all scenes to only the part we are interested in.\n",
    "\n",
    "The simplest way to do this is to create a vector layer which contains only 4 points defining a rectangular area.\n",
    "We can use QGIS and the handy plugin \"Rectangles Ovals Digitizing\"\n",
    "\n",
    "This will generate a shapefile containing the vector layer.\n",
    "Will refer to this as the **ROI vector**\n",
    "**Take care to specify the same reference system as the Landsat images to avoid problems later**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that using a GIS system:\n",
    "* We can easily generate and modify geographic data\n",
    "* We can easily change the visualisation of the data\n",
    "* We can save a GIS project keeping track of the selected data and our visualization choices\n",
    "\n",
    "**Be careful saving a project does not save the data**. If you delete the layer source it will also be missing\n",
    "in you project (there is only a link stored to the datafile).\n",
    "\n",
    "\n",
    "The last step we have to perform before we can start using the tool is to\n",
    "\n",
    "#### Create a vector layer containing ground truth data \n",
    "The layer is in form of polygons with an attribute containing the labels of your desired classes\n",
    "within your region of interest. We will refer to this as **Train/Test vector**.\n",
    "\n",
    "Let's use again QGIS to generate one. \n",
    "**Take care to specify the same reference system as the Landsat images to avoid problems later**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We see that using QGIS and the **OpenLayers** plugin we can very easily generate ground truth data.\n",
    "* We can add columns with different content types to the geometry of a vector layer.\n",
    "* In the Attribute Table of a layer we can change the content of the columns. \n",
    "\n",
    "Of course if you have better data you can also convert it to vector format and use this.\n",
    "\n",
    "#### Let's try to run a classification process with SatEx\n",
    "\n",
    "The tool is located in your home directory \"~/REM_satex_plugin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the tool directory you will find a file called **config.ini**\n",
    "Open it in a text editor and modify the content according to the instructions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"gedit /home/sysop/REM_satex_plugin/config.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the file has the title **[preprocessing]**.\n",
    "These are the variables for the preprocessing modify them accordingly\n",
    "1. ls_path: this is the **Band directory**, i.e., where the bands of the satellite image are\n",
    "2. roi: this is the path to the **ROI vector** we created\n",
    "3. out_fname: this is the file that will be created by the preprocessing algorithm\n",
    "\n",
    "An example could look like\n",
    "\n",
    ">ls_path = /home/sysop/Desktop/RS_Data/Lima/LC08_L1TP_007068_20161217_20170316_01_T1\n",
    "\n",
    ">roi = /home/sysop/Desktop/RS_Data/Lima/roi.shp\n",
    "\n",
    ">out_fname = /home/sysop/Desktop/RS_Data/Lima/pp.tif\n",
    "\n",
    "The second part of the file has the title **[classification]**.\n",
    "1. raster: This is the preprocessed generated by the preprocessing algorithm (out_fname in the preprocessing)\n",
    "2. in_train: This is the **Train/Test vector**\n",
    "3. out_fname: This is the classification output that will be generated by the classification algorithm.\n",
    "4. label: This is the name you assigned to the field where you specified the different class values (integers)\n",
    "5. sieve: This is the minimum size of pixels for a region, smaller ones will be joined to their neighbors\n",
    "6. external: In case you want to use a previously trained SVM specify its file here \n",
    "\n",
    "An example for a on-the fly SVM classification looks like this:\n",
    ">raster = /home/sysop/Desktop/RS_Data/Lima/pp.tif\n",
    "\n",
    ">in_train = /home/sysop/Desktop/RS_Data/Lima/ground_truth.shp\n",
    "\n",
    ">out_fname = /home/sysop/Desktop/RS_Data/Lima/classes.tif\n",
    "\n",
    ">label = class\n",
    "\n",
    ">sieve = 4\n",
    "\n",
    ">external = \n",
    "\n",
    "Save the file and close it. Once this is done we can run the tool.\n",
    "First we change within python to the directory of the tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/sysop/REM_satex_plugin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets run the tool as script with the config.ini we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 scene(s) in /home/sysop/Desktop/RS_Data/Lima/LT05_L1TP_007068_20060426_20161122_01_T1/\n",
      "Using /home/sysop/Desktop/RS_Data/Lima/roi.shp as ROI\n",
      "Found 7 bands (if present, excluding B8 and BQA) for scene LT05 \n",
      "Cropped band LT05_L1TP_007068_20060426_20161122_01_T1_B3.TIF to ROI\n",
      "Cropped band LT05_L1TP_007068_20060426_20161122_01_T1_B5.TIF to ROI\n",
      "Cropped band LT05_L1TP_007068_20060426_20161122_01_T1_B7.TIF to ROI\n",
      "Cropped band LT05_L1TP_007068_20060426_20161122_01_T1_B1.TIF to ROI\n",
      "Cropped band LT05_L1TP_007068_20060426_20161122_01_T1_B6.TIF to ROI\n",
      "Cropped band LT05_L1TP_007068_20060426_20161122_01_T1_B4.TIF to ROI\n",
      "Cropped band LT05_L1TP_007068_20060426_20161122_01_T1_B2.TIF to ROI\n",
      "Concatenated bands for scene LT05\n",
      "Merged 1 different scenes to /home/sysop/Desktop/RS_Data/Lima/pp_L5.tif\n",
      "Processing sucessfully completed\n",
      "Deleting temporary files\n",
      "Processing successfully completed, see log for details\n",
      "FIX:overwriting utils function otb_train_cls due to bug in otb\n",
      "Calculated image statistics /home/sysop/Desktop/RS_Data/Lima/pp_L5_stats.xml for /home/sysop/Desktop/RS_Data/Lima/pp_L5.tif\n",
      "test_file: /home/sysop/Desktop/RS_Data/Lima/ground_truth_L5_test.shp\n",
      "Splitted ground truth data set in /home/sysop/Desktop/RS_Data/Lima/ground_truth_L5_train.shp (~80%) and /home/sysop/Desktop/RS_Data/Lima/ground_truth_L5_test.shp (~20%)\n",
      "Trained image classifier using /home/sysop/Desktop/RS_Data/Lima/pp_L5.tif and /home/sysop/Desktop/RS_Data/Lima/ground_truth_L5_train.shp\n",
      "Image /home/sysop/Desktop/RS_Data/Lima/pp_L5.tif classified as /home/sysop/Desktop/RS_Data/Lima/classes_L5.tif\n",
      "/home/sysop/Desktop/RS_Data/Lima/classes_L5.tif /home/sysop/Desktop/RS_Data/Lima/ground_truth_L5_CM.csv /home/sysop/Desktop/RS_Data/Lima/ground_truth_L5_test.shp class\n",
      "Confusion matrix calculated on classified image /home/sysop/Desktop/RS_Data/Lima/classes_L5.tif with test set /home/sysop/Desktop/RS_Data/Lima/ground_truth_L5_test.shp saved as /home/sysop/Desktop/RS_Data/Lima/ground_truth_L5_CM.csv\n",
      "Processing completed\n",
      "Processing successfully completed, see log for details\n"
     ]
    }
   ],
   "source": [
    "run -i run_as_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happened\n",
    "\n",
    "**Preprocessing**\n",
    "* The module first checked the number of different scenes that are present in the **Band directory** \n",
    "* and then **cropped** each band for each scene to the region of interest as specified by **ROI vector** (checking that\n",
    "  they at least partly overlap) \n",
    "* and **stack** the bands into a single file for each of the scenes. \n",
    "* These files are created in the same directory as you specified for the output file \n",
    "  with a file suffix like *\\*\\_satex\\_mul.TIF*. \n",
    "* Finally, they are **virtually mosaiced** in the file that is specified in the output file you specified\n",
    "\n",
    "**Note:** The resulting \\*.vrt file only links the *\\*\\_satex\\_mul.TIF*\n",
    "files created in the **Band directory** and does not contain the actual\n",
    "data! If you need to transfer the file save it as a regular \\*.TIF file!\n",
    "\n",
    "**Classification**\n",
    "\n",
    "* The **Training/Testing vector** is split in *\\*\\_test.shp* and *\\*\\_train.shp*  (~80% training and ~20% testing, \n",
    "  balanced sampling)\n",
    "\n",
    "* The features of the *\\*\\_train.shp* file are then used to train a SVM (libsvm implementation of OTB)\n",
    "* The resulting model *\\*\\_svmModel.svm* is then used to classify the *Input raster* \n",
    "* Features of the *\\*\\_test.shp* file are then used to calculate a Confusion Matrix (*\\*\\_CM.csv*)\n",
    "\n",
    "\n",
    "### Judge the quality of the classification\n",
    "\n",
    "Let's first take a look at the test statistics we ran using 20% of the data we provided.\n",
    "You will find a csv file containing the Confusion Matrix created in the\n",
    "same location as your **Training/Testing vector** with the same name,\n",
    "but ending with *\\*\\_CM.csv* instead of *\\*.shp*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"libreoffice --calc /home/sysop/Desktop/RS_Data/Lima/ground_truth_CM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The task now is to gradually improve the model by \n",
    "1. adding or changing ground truth data, and\n",
    "2. re-running the classification.\n",
    "\n",
    "Hints: \n",
    "* After each rerun check the confusion matrix (you can add a link to the file in libre office and simply update it)\n",
    "* In Qgis you can add the created \"test.shp\" layer and check which labels are wrongly assigned comparing it to the classified raster layer. \n",
    "\n",
    "You will iteratively reach a better classification result and will be able to find a classification with reasonable quality following this simple approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced\n",
    "\n",
    "### Change detection\n",
    "\n",
    "We can use satellite scenes taken at different time steps to analyse change between the two points in time.\n",
    "In this exercise we will do a simple change detection just distinguishing the approximate age of\n",
    "built-up regions, not considering a change in composition.\n",
    "\n",
    "Let's take a look back at the Data available from the [Earth Explorer](https://earthexplorer.usgs.gov/)\n",
    "In theory you can get data way back until the 70's. Their availability depends on the region and is not always\n",
    "given.\n",
    "Let's get the oldest scene available (should be already in the RS_data directory on the USB key).\n",
    "\n",
    "There are some draw backs for the older Landsat scenes:\n",
    "\n",
    "* The global coverage is low\n",
    "* The temporal density is low\n",
    "* Spatial resolution might be lower (MSS 57x79 m)\n",
    "* The spectral resolution might be lower (less channels)\n",
    "* The radiometric resolution might be lower (MSS 6 bit vs OLI 12 bit)\n",
    "\n",
    "Nevertheless, usually for the purpose of exposure modeling it is enough to distinguish built-up and \n",
    "non-built up area in the older scenes. We can just overlay the classification of the Landsat 8 scene\n",
    "with more detailed information.\n",
    "\n",
    "We are interested in present day conditions. From the older scenes we can determine lower age boundaries\n",
    "of the strata and get an idea about the expected age tendency of buildings within a part of a town.\n",
    "\n",
    "You can use the SatEx code also for older scenes. \n",
    "The only things to take care of is to \n",
    "1. store the bands in a different directory than the scenes from other sensors, and \n",
    "2. check that the band raster names end with *_Bx.tif or *_Bx.TIF (x is the number e.g.,1,2,3..)\n",
    "\n",
    "For the labeling of training samples the best approach is to look at the Landsat scene and use the recent high resolution Quickbird image of Google for verification. **BUT be careful**, especially for older scenes use Google only as help.\n",
    "The content of the scene and the recent Google images might be different due to changes in the landuse.\n",
    "These **changes** is what we actually want to identify! \n",
    "\n",
    "Now we can modify the *config.ini* accordingly and rerun the SatEx code above.\n",
    "\n",
    "\n",
    "#### Combining the information\n",
    "\n",
    "--> R notebook\n",
    "\n",
    "\n",
    "\n",
    "### Object (segment) based analysis\n",
    "\n",
    "A more complex approach to the task of landuse classification is to first segment the scene in homogeneous regions,\n",
    "and afterwards classifying these segments.\n",
    "In this case we can consider not only the spectral content but also textural features etc.\n",
    "**But assigning labels to the segments is not always easy!**\n",
    "\n",
    "The steps require some experience, thus for the purpose of this training we only\n",
    "We want to show you an example classification using the following procedure:\n",
    "1. Segment the scene, using the Felszenswalb algorithm for segmentation\n",
    "2. Training a Support Vector Machine on some  the segments\n",
    "3. Running a classification using the trained SVM on the whole scene\n",
    "\n",
    "For the purpose of the exercise try the segmentation algorithms available in the **Processing Toolbox** of **Qgis**\n",
    "on the preprocessed scene generated before.\n",
    "Once you have a segmentation try to label the resulting segmentings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
